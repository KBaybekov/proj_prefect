# Спецификация пайплайнов (v1)
# Заметки:
# - В ключе - название пайплайна (без пробелов)
# - Версия: порядковый номер + тэг Nextflow-пайплайна
# - Описание: описание пайплайна на русском языке
# - Каждый пайплайн содержит: скрипт для формирования входного samplesheet и одну Nextflow задачу.
# - Условия в `requires` - простые правила фильтрации в БД полям в коллекции "samples".
# - Команда собирается с помощью плейсхолдеров Jinja2-like {{ placeholders }} из контекста.
# - Требования Slurm передаются в Nextflow через параметры/профили.
# - В Outputs указаны ожжидаемые файлы; в пути могут быть плейсхолдеры.

teloseq_example: 
  version: "1.0.0"
  description: Example pipeline spec for telomere analysis (placeholder)

  requires:
    mode: all  # all | any
    rules:
    - scope: sample         # sample | batch | file
      path: "attributes.organism"  # dot-path in the chosen scope
      op: "eq"              # eq | ne | in | nin | exists | regex | gte | lte
      value: "Homo sapiens"
    - scope: file
      path: "kind"
      op: "in"
      value: ["fastq", "fastq.gz"]

  grouping:
    enabled: false            # if true, group multiple samples into one run by key below
    by: null                  # e.g., "batch_id"

  inputs:
    - label: reads
      scope: sample           # where to resolve from (sample/batch/files query)
      find:
        glob: "{{ sample.paths.fastq_dir }}/{{ sample.sample_id }}*.fastq.gz"
        min_count: 1
        min_size_mb: 1
      constraints:
        # optional hints; not enforced by code if unknown
        paired: false
        compression: "gz"

  context:                     # values available for template substitution
    sample_keys: ["sample_id", "batch_id", "subject_id"]
    extra:
      work_root: "/mnt/cephfs/work/nextflow"
      out_root: "/mnt/cephfs/out"

  command:
    template: >
      nextflow run wf-teloseq
        -profile slurm
        --reads "{{ inputs.reads|join(',') }}"
        --outdir "{{ context.extra.out_root }}/{{ sample.sample_id }}/teloseq"
        -with-report "{{ context.extra.out_root }}/{{ sample.sample_id }}/teloseq/report.html"
        -with-trace "{{ context.extra.out_root }}/{{ sample.sample_id }}/teloseq/trace.csv"
        -with-timeline "{{ context.extra.out_root }}/{{ sample.sample_id }}/teloseq/timeline.html"
    substitutions:
      # How to build inputs for the template (Jinja-like)
      inputs.reads:
        from: files            # files selected in inputs
        where_label: reads
        attr: path             # take file path
        join_by: ","

  slurm:
    partition: "cpu_nodes"
    time: "04:00:00"
    cpus: 8
    mem_mb: 32000
    gpus: 0
    qos: null
    account: null

  outputs:
    - name: teloseq_summary
      required: true
      files:
        - "{{ context.extra.out_root }}/{{ sample.sample_id }}/teloseq/summary.tsv"
    - name: teloseq_bam
      required: false
      files:
        - "{{ context.extra.out_root }}/{{ sample.sample_id }}/teloseq/aln.bam"

  reports:
    collect:
      trace_csv: true
      report_html: true
      timeline_html: true
    store_paths_in:
      collection: "files"       # where to upsert file documents
      link_to_run: true

  results:
    # Lightweight result fields without tool-specific parsing (parsers deferred)
    # Example of shell extraction (optional, can be disabled now):
    populate:
      - name: output_exists
        type: boolean
        via: "exists"
        args:
          path: "{{ context.extra.out_root }}/{{ sample.sample_id }}/teloseq/summary.tsv"
    upsert:
      collection: "runs"
      match_keys: ["pipeline", "sample_id", "inputs_hash"]
      set:
        pipeline: "{{ name }}"
        pipeline_version: "{{ version }}"
        sample_id: "{{ sample.sample_id }}"
        batch_id: "{{ sample.batch_id }}"
        inputs_hash: "{{ hash(inputs.reads) }}"
        outputs: "@outputs"     # special token: resolved file list

  retry_policy:
    max_retries: 2
    backoff_sec: 600

  concurrency:
    allow_parallel_on_same_sample: true
    requires_sequencing: []      # list pipelines that must precede this one (optional)

