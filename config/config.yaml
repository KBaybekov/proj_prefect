common:
  log: "./logs/watchdog.log"

# DB INFO
database:
  host: "vu10-2-002"
  name: "nanopore"
  user: "guest"
  password: "guest"
  timeout: "100"
  # Префикс для коллекций в БД
  collection_prefix: "test_"
  # Конфиг БД для DAO: коллекции и их индексы.
  # Направления: ASC/DESC. Доп. опции (unique/sparse/partialFilterExpression) — по месту.
  collections:
    files:
      indexes:
        - name: ix_name
          keys: [["name", "ASC"]]
        - name: ix_batch_sample
          keys: [["batch", "ASC"], ["sample", "ASC"]]
        - name: ix_stat_dev_ino
          unique: true
          keys: [["dev", "ASC"], ["ino", "ASC"]]
        - name: ix_fingerprint
          unique: true
          keys: [["fingerprint", "ASC"]]

    batches:
      indexes:
        - name: ix_name
          keys: [["name", "ASC"]]
        - name: ix_curation
          keys: [["needs_curation", "ASC"]]
        - name: ix_status
          keys: [["status", "ASC"]]
        - name: ix_updated_at
          keys: [["updated_at", "DESC"]]
        - name: ix_fingerprint
          unique: true
          keys: [["fingerprint", "ASC"]]

    samples:
      indexes:
        - name: ix_name
          keys: [["name", "ASC"]]
        - name: uq_batches
          keys: [["batches", "ASC"]]
        - name: ix_status
          keys: [["status", "ASC"]]
        - name: ix_curation
          keys: [["needs_curation", "ASC"]]
        - name: ix_updated_at
          keys: [["modified", "DESC"]]
        - name: ix_fingerprint
          unique: true
          keys: [["fingerprint", "ASC"]]

    curations:
      indexes:
        - name: ix_name
          keys: [["name", "ASC"]]
        - name: ix_fingerprint
          unique: true
          keys: [["fingerprint", "ASC"]]

    human:
      indexes:
        - name: ix_sample
          keys: [["sample", "ASC"]]
        - name: ix_created_at
          keys: [["created_at", "DESC"]]

# FILESYSTEM INFO
filesystem:
  source_dir: "/common_share/github/proj_prefect/test/data/raw/"
  # директория для хранения стандартизированных ссылок на файлы
  link_dir: "/common_share/github/proj_prefect/test/data/links/"
  result_dir: "/common_share/github/proj_prefect/test/data/result/"
  processing_dir: "/common_share/github/proj_prefect/test/data/tmp/"
  source_files_extensions: "fast5,pod5,fastq.gz"
  # Пауза перед записью в БД в секундах (для исключения множественных обращений к БД)
  db_writing_debounce: 10
  # Время перед регистрацией модификации файла в секундах (для исключения генерации метаданных для файла во время его копирования)
  file_modification_debounce: 5
  # Пауза между проверками на наличие данных для загрузки в БД в секундах
  db_update_interval: 30

# TASK SCHEDULER INFO
scheduler:
  db_poll_interval: 10
  # Директория с файлами шейперов
  shapers_dir: "/raid/kbajbekov/common_share/github/proj_prefect/data/data_shapers/"
  # Файл конфигурации организации для Nextflow
  nextflow_config: "/path-to-nextflow.config"
  # Шаблон для запуска SBATCH-скрипта
  start_script_template: "/path-to-slurm_template"
  # Узел, на котором будет запущена head-задача
  head_job_node: "vu10-2-027"

  slurm:
    user: "kbajbekov"
    poll_interval: 5
    # Размеры очередей для задач с разными типами сортировки. Сумма очередей должна быть равна main_queue_size!
    # Задачи, попадающие в SJF-очередь, будут выполняться последовательно
    sjf_queue_size: 2
    # Задачи, попадающие в LJF-очередь, будут выполняться параллельно
    ljf_queue_size: 14

  # Вспомогательные данные, необходимые для пайплайнов
  service_data:
    reference_hg38: "hg38.fa"
    reference_hg38_t2t: "hg38_t2t.fa"

  pipelines:
    # При изменении версии пайплайнов запускается реанализ всего даунстрима
    # В названии раздела указывается название и версия пайплайна
    ont-basecalling_v1-0-0:
      name: ont-basecalling
      version: v1.0.0
      data_shaper: data_shaper_ont-basecalling_v1-0-0.py
      # conditions: прописываются условия, позволяющие исключить как уже обработанные образцы,
      # так и не обработанные образцы, не подходящие по входным параметрам
      conditions:
        - field: status
          type: eq       # Равенство
          value: indexed
        #      - type: ne       # Не равно (поддержка массива)
        #        field: pipeline_basecalling_{{ modifications }}_status
        #        value: ["ok", "fail", "running"]
        #      - type: gte      # Больше или равно
        #        field: total_size
        #        value: 10
        #      - type: exists   # Проверка наличия поля
        #        field: sample_id
      # Тип сортировки и показатель, по которому будет производиться сортировка
      sorting: "SJF"
      # Дополнительные параметры SBATCH для запуска головного задания
      # Указываются как параметр: значение
      # slurm_options:
      #   partition: "gpu"
      # nextflow_variables:
      #   NXF_OFFLINE: "true"
      # Указывается время выполнения пайплайна на стандартном образце. Необходим для корректного формирования очередей. Формат: DAYS-HH:MM
      timeout: "3-00:00"
      environment_variables:
        GPUS_FOR_BASECALLING: "1"
        GPU_IDS_FOR_BASECALLING: "6"
      # !!! ВНИМАНИЕ !!! При изменении шаблона команды необходимо изменять и соответствующий шейпер
      command_template: |
        nextflow \
        run nxf-csp/ont-basecalling \
        -c {{ NXF_CFG }} \
        -name nxf_{{ JOB_NAME }}_${TIMESTAMP} \
        --input {{ INPUT_SAMPLESHEET }} \
        --sample {{ SAMPLE }} \
        --run_id {{ NXF_RUN_ID }} \
        --outdir {{ OUTPUT_DIR }} \
        -resume

      # Список файлов, относящихся к образцу, которые будут использоваться в пайплайне
      # Структура:
      # (обяз.) название_группы(произвольное, будет использоваться шейпером)
      # # Затем указывается список источников, от 1 штуки. В каждом источнике указываются слеедующие элементы:
      #   (обяз.) source: название_источника (sample/result/shaper):
      #         - Если указывается sample, то подразумевается, что файлы будут браться из атрибута files
      #         - Если shaper, то данные появятся в результате выполнения шейпера
      #         - Если result, то данные будут браться из атрибута result (обязателен пункт attributes)
      #   (опц.) attributes: нитка атрибутов из источника, по которым нужно вести поиск (например, outputs.data.ubam)
      #   (обяз.) file_mask: список масок, по которым будут искаться файлы. Все файлы, найденные по указанным маскам, будут добавлены в указанную группу!
      #   (опц.) requirements: список требований к файлам. Возможные требования: not_empty, realpath, size_gte, size_lte, is_dir, is_file, is_symlink.  
      #   (обяз.) condition: тип условия наличия данных этой группы.
      #        Возможные значения:
      #           required (данные необходимы для обработки)
      #           preferred (данные желательны для обработки)
      input_data:
        ont_source_files:
          - source: sample
            file_mask: 
              - "*.fast5"
              - "*.pod5"
            requirements:
              - is_file
              - not_empty
              - realpath
            condition: "required"
        nxf_samplesheet:
          - source: shaper
            file_mask: 
              - "*.tsv"
              - "*.csv"
            requirements:
              - is_file
              - realpath
              - size_gte 5
            condition: "required"

      # словарь вида {тип_файлов: маска}
      expected_output_data:
        data:
          ubam: "*.ubam"
        qc:
          sequali_json: "*_sequali.json"
          sequali_html: "*_sequali.html"
          multiqc_report: "*_multiqc_report.html"

